test data loss : 0.6931471824645996
test data accyracy : 0.5

training history accuracy
0.5060416460037231
0.49687498807907104
0.5020833611488342
0.5020833611488342
0.4983333349227905
0.5020833611488342
0.492083340883255
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.4945833384990692
0.5020833611488342
0.49291667342185974
0.5020833611488342
0.4945833384990692
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.492083340883255
0.4970833361148834
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.4933333396911621
0.5020833611488342
0.49666666984558105
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.4908333420753479
0.49666666984558105
0.4933333396911621
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.4945833384990692
0.4970833361148834
0.5020833611488342

training history val accuracy
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264

training history loss
0.6980883479118347
0.6931829452514648
0.6931667327880859
0.6932263970375061
0.6931660771369934
0.6932287216186523
0.6931983828544617
0.6931698322296143
0.6931627988815308
0.6931679844856262
0.6932030916213989
0.6931881308555603
0.6932100057601929
0.6931751370429993
0.6932089328765869
0.6931793689727783
0.6931721568107605
0.6931660771369934
0.693180501461029
0.6931807398796082
0.6931852102279663
0.6931613683700562
0.6931684613227844
0.6931739449501038
0.6931813955307007
0.6931668519973755
0.6931674480438232
0.6932016015052795
0.6931676268577576
0.6931633949279785
0.6931667327880859
0.6931902170181274
0.69318026304245
0.6932138204574585
0.6931915879249573
0.6931951642036438
0.6931814551353455
0.6931847929954529
0.6931992173194885
0.6932358145713806
0.6931660771369934
0.6931666135787964
0.6931827664375305
0.693206250667572
0.6931586265563965
0.6932060122489929
0.6931816935539246
0.6932157874107361
0.6931788921356201
0.6931911706924438
0.6931701898574829

training history val loss
0.6931687593460083
0.6931732892990112
0.693191647529602
0.6932134032249451
0.6931588649749756
0.6932482123374939
0.6932284832000732
0.6932199597358704
0.6932305693626404
0.6932461261749268
0.6932501792907715
0.6932230591773987
0.6931915879249573
0.6932030916213989
0.6931732892990112
0.6932356953620911
0.6932340860366821
0.6932100653648376
0.693192720413208
0.6932330131530762
0.6931532025337219
0.693227231502533
0.6932143568992615
0.6932610869407654
0.6932462453842163
0.6931828260421753
0.6932541131973267
0.6932353973388672
0.6931954622268677
0.6932255625724792
0.6932442784309387
0.6932196617126465
0.6932053565979004
0.6932331323623657
0.6932169795036316
0.6931817531585693
0.6932314038276672
0.6932069659233093
0.6932709813117981
0.6931601166725159
0.6931750774383545
0.6932207942008972
0.6932767629623413
0.6931900978088379
0.693250298500061
0.6933553814888
0.6932534575462341
0.6931623816490173
0.6931858062744141
0.6932546496391296
0.693230152130127