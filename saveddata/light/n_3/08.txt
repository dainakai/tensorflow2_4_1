test data loss : 0.6931472420692444
test data accyracy : 0.5

training history accuracy
0.4908333420753479
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.4950000047683716
0.49562498927116394
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.49291667342185974
0.48750001192092896
0.5020833611488342
0.5020833611488342
0.4983333349227905
0.5020833611488342
0.5020833611488342
0.49291667342185974
0.5020833611488342
0.5020833611488342
0.4879166781902313
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.4933333396911621
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.49166667461395264
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.49541667103767395
0.5020833611488342
0.5020833611488342
0.5020833611488342
0.49041667580604553
0.5020833611488342
0.5020833611488342
0.5020833611488342

training history val accuracy
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264
0.49166667461395264

training history loss
0.6949010491371155
0.693147599697113
0.6931983232498169
0.6931843161582947
0.6931816339492798
0.693284809589386
0.6931936144828796
0.6932152509689331
0.6931731700897217
0.6931723356246948
0.6931829452514648
0.6931723952293396
0.6932212114334106
0.6931730508804321
0.693182647228241
0.6932075023651123
0.6932281255722046
0.6931653618812561
0.6931710839271545
0.6931635141372681
0.693172037601471
0.6931623816490173
0.6931840181350708
0.6931842565536499
0.6932089924812317
0.6932078003883362
0.6931906938552856
0.6931577324867249
0.6932081580162048
0.6931717395782471
0.6931648850440979
0.6931627988815308
0.6931820511817932
0.6931977868080139
0.6932053565979004
0.693181037902832
0.6931552290916443
0.6931691765785217
0.6931827664375305
0.6931628584861755
0.6932340860366821
0.6931781768798828
0.6932079792022705
0.6931763887405396
0.6931706070899963
0.6931992173194885

training history val loss
0.6931707859039307
0.6932399272918701
0.6932138800621033
0.6932018995285034
0.6932322978973389
0.6932050585746765
0.6931838393211365
0.6932656764984131
0.6932019591331482
0.6932218670845032
0.6932359337806702
0.6932163238525391
0.6932731866836548
0.6932387351989746
0.6931898593902588
0.6931484937667847
0.6932007074356079
0.6931917667388916
0.6931769847869873
0.693274736404419
0.6932281851768494
0.6932541131973267
0.6932552456855774
0.6932187080383301
0.6932089924812317
0.693212628364563
0.6933245062828064
0.6932130455970764
0.6932196617126465
0.6932026147842407
0.693187952041626
0.6932169198989868
0.6932312846183777
0.693253755569458
0.6931528449058533
0.6932676434516907
0.6932153105735779
0.6932026743888855
0.6931951642036438
0.6932421326637268
0.693255603313446
0.6932007074356079
0.693206787109375
0.6932523846626282
0.6932246088981628
0.6932576894760132